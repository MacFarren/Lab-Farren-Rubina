#  Lab9 - MLOps Pipeline con Apache Airflow

[![Airflow](https://img.shields.io/badge/Apache%20Airflow-2.6.3-blue.svg)](https://airflow.apache.org/)
[![Python](https://img.shields.io/badge/Python-3.8+-green.svg)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-blue.svg)](https://www.docker.com/)
[![ML](https://img.shields.io/badge/ML-Scikit--Learn-orange.svg)](https://scikit-learn.org/)

##  DescripciÃ³n del Proyecto

Sistema de pipeline MLOps automatizado para predicciÃ³n de contrataciÃ³n usando Apache Airflow. El proyecto implementa dos enfoques arquitectÃ³nicos (lineal y dinÃ¡mico) para entrenar mÃºltiples modelos de Machine Learning y desplegarlos mediante una interfaz web interactiva.

###  Objetivos Principales

- **AutomatizaciÃ³n**: Pipeline completo de ML usando Apache Airflow
- **Escalabilidad**: ComparaciÃ³n entre ejecuciÃ³n secuencial vs paralela
- **ProductivizaciÃ³n**: Interfaz web para predicciones en tiempo real
- **Robustez**: Manejo de errores y recuperaciÃ³n automÃ¡tica

##  Arquitectura del Sistema

```mermaid
graph TD
    A[Datos de Entrada] --> B[DAG Lineal]
    A --> C[DAG DinÃ¡mico]
    B --> D[Entrenamiento Secuencial]
    C --> E[Entrenamiento Paralelo]
    D --> F[SelecciÃ³n Mejor Modelo]
    E --> F
    F --> G[Gradio Interface]
    G --> H[PredicciÃ³n Usuario]
```

###  Componentes del Pipeline

1. **Ingesta de Datos**: Carga y validaciÃ³n automÃ¡tica
2. **Preprocesamiento**: Limpieza y transformaciÃ³n de features
3. **Entrenamiento**: MÃºltiples algoritmos ML (RandomForest, SVM, LogisticRegression)
4. **EvaluaciÃ³n**: MÃ©tricas de rendimiento y selecciÃ³n de mejor modelo
5. **Despliegue**: SerializaciÃ³n y disponibilidad del modelo
6. **Interfaz**: Web UI para predicciones interactivas

##  Estructura del Proyecto

```
Lab9/
â”œâ”€â”€  dags/                        # Definiciones de DAGs
â”‚   â”œâ”€â”€ dag_lineal.py              # Pipeline secuencial
â”‚   â”œâ”€â”€ dag_dynamic.py             # Pipeline paralelo
â”‚   â”œâ”€â”€ hiring_functions.py        # Funciones para DAG lineal
â”‚   â””â”€â”€ hiring_dynamic_functions.py # Funciones para DAG dinÃ¡mico
â”œâ”€â”€  2025-11-04/                 # Resultados de ejecuciÃ³n
â”‚   â””â”€â”€ models/                    # Modelos entrenados
â”œâ”€â”€ docker-compose.yaml            # ConfiguraciÃ³n Docker
â”œâ”€â”€ requirements.txt               # Dependencias Python
â”œâ”€â”€ train_models.py               # Script entrenamiento standalone
â”œâ”€â”€ gradio_robust.py              # Interfaz web robusta
â”œâ”€â”€ vale_data.json                # Datos de prueba
â””â”€â”€ README.md                     # Este archivo
```

##  InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos

- **Docker** y **Docker Compose** instalados
- **Puerto 8080** disponible para Airflow UI
- **Puerto 7861** disponibles para Gradio

### InstalaciÃ³n RÃ¡pida

```bash
# . Iniciar servicios
docker compose up -d --build

# 2. Esperar inicializaciÃ³n (2-3 minutos)
# Verificar logs si es necesario
docker compose logs -f airflow
```

###  VerificaciÃ³n de InstalaciÃ³n

```bash
# Verificar contenedores activos
docker compose ps

# Verificar logs de Airflow
docker compose logs airflow | tail -20

# Acceder a Airflow UI
# http://localhost:8080 (admin/admin)
```

## ðŸŽ® Uso del Sistema

### 1.  Airflow Dashboard

1. **Acceder**: [http://localhost:8080](http://localhost:8080)
2. **Credenciales**: `admin` / `admin`
3. **Activar DAGs**: Hacer toggle en `dag_lineal` y `dag_dynamic`
4. **Ejecutar**: Click en "Trigger DAG" o esperar programaciÃ³n automÃ¡tica

### 2. Monitoreo de EjecuciÃ³n

- **Graph View**: Visualizar dependencias y estados
- **Tree View**: Historial de ejecuciones
- **Gantt View**: AnÃ¡lisis de tiempos de ejecuciÃ³n
- **Task Duration**: MÃ©tricas de rendimiento

### 3. Interfaz de PredicciÃ³n

```bash
# Iniciar Gradio (opcional - ya incluido en pipeline)
docker exec -it <container-id> python /opt/airflow/gradio_robust.py

# Acceder a la interfaz
# http://localhost:7861
```

##  AnÃ¡lisis Comparativo

### DAG Lineal vs DAG DinÃ¡mico

| Aspecto | DAG Lineal | DAG DinÃ¡mico |
|---------|------------|---------------|
| **EjecuciÃ³n** | Secuencial | Paralela |
| **Tiempo Total** | ~5-8 minutos | ~3-5 minutos |
| **Uso de Recursos** | Bajo | Alto |
| **Complejidad** | Simple | Avanzada |
| **Escalabilidad** | Limitada | Excelente |

### Rendimiento de Modelos

```python
# Resultados tÃ­picos del entrenamiento
Modelos_Performance = {
    'RandomForest': {'accuracy': 0.9167, 'tiempo': '45s'},
    'SVM': {'accuracy': 0.8633, 'tiempo': '32s'},
    'LogisticRegression': {'accuracy': 0.9033, 'tiempo': '12s'}
}
```

##  ConfiguraciÃ³n Avanzada

### Variables de Entorno

```yaml
# docker-compose.yaml
environment:
  - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
  - AIRFLOW__CORE__LOAD_EXAMPLES=False
  - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
```

### PersonalizaciÃ³n de DAGs

```python
# Configurar intervalos de ejecuciÃ³n
default_args = {
    'schedule_interval': '@daily',  # Cambiar a '@hourly' para mayor frecuencia
    'max_active_runs': 1,
    'catchup': False
}
```

##  Troubleshooting

### Problemas Comunes

1. **Puerto 8080 ocupado**
   ```bash
   # Cambiar puerto en docker-compose.yaml
   ports:
     - "8081:8080"  # Usar puerto 8081 en lugar de 8080
   ```

2. **Memoria insuficiente**
   ```bash
   # Aumentar recursos Docker
   # Docker Desktop > Settings > Resources > Memory: 4GB+
   ```

3. **DAGs no aparecen**
   ```bash
   # Verificar volÃºmenes montados
   docker exec -it <container> ls -la /opt/airflow/dags/
   
   # Reiniciar servicios
   docker compose restart
   ```

### Logs y Debugging

```bash
# Logs generales
docker compose logs airflow

# Logs especÃ­ficos de tarea
docker exec -it <container> airflow tasks test dag_lineal train_models 2025-11-04

# Logs de Gradio
docker exec -it <container> tail -f /opt/airflow/gradio.log
```

##  DocumentaciÃ³n TÃ©cnica

### APIs Utilizadas

- **Apache Airflow**: OrquestaciÃ³n de workflows
- **Scikit-Learn**: Algoritmos de Machine Learning
- **Gradio**: Interfaz web interactiva
- **Pandas**: ManipulaciÃ³n de datos
- **Joblib**: SerializaciÃ³n de modelos

### MÃ©tricas de EvaluaciÃ³n

```python
# MÃ©tricas implementadas
metrics = [
    'accuracy_score',
    'classification_report', 
    'confusion_matrix',
    'cross_val_score'
]
```


### Comandos de DiagnÃ³stico RÃ¡pido

```bash
# Estado del sistema
docker compose ps
docker system df
docker compose logs --tail=50 airflow

# Reinicio completo
docker compose down
docker compose up -d --build
```


```bash
# Monitoreo continuo
docker compose logs -f airflow | grep -E "(ERROR|SUCCESS|INFO)"
```