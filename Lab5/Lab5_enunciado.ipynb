{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tgm8mCA9Dp3"
      },
      "source": [
        "# Laboratorio 5: Clasificaci√≥n ü§ó\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos - Primavera 2025</strong></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Kc_ibM9GXH"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Diego Cortez, Gabriel Iturra\n",
        "- Auxiliares: Melanie Pe√±a, Valentina Rojas\n",
        "- Ayudantes: Nicol√°s Cabello, Cristopher Urbina"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9dUSltr9JrN"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
        "\n",
        "- Nombre de alumno 1: Sebasti√°n Rubina\n",
        "- Nombre de alumno 2: Maximiliano Farren"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC1IloytrsAx"
      },
      "source": [
        "### **Link de repositorio de GitHub:** [Repositorio](https://github.com/MacFarren/Lab-Farren-Rubina)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBa48PDF9OHw"
      },
      "source": [
        "### Temas a tratar\n",
        "- Clasificaci√≥n en problemas desbalanceados\n",
        "- Lightgbm y xgboost\n",
        "- Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkhnnMx49Qrh"
      },
      "source": [
        "## Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Fecha de entrega: Entregas Martes a las 23:59.\n",
        "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria, pero se recomienda **fuertemente** asistir.\n",
        "- <u>Prohibidas las copias</u>. Cualquier intento de copia ser√° debidamente penalizado con el reglamento de la escuela.\n",
        "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est√©n en u-cursos no ser√°n revisados. Recuerden que el repositorio tambi√©n tiene nota.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Pueden usar cualquier material del curso que estimen conveniente.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxzJ48Vv8quO"
      },
      "source": [
        "\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "- Comprender c√≥mo trabajar con problemas de clasificaci√≥n con clases desbalanceadas.\n",
        "- Aplicar los modelos lightgbm y xgboost.\n",
        "- Practicar Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-ao0mOU64Ru"
      },
      "source": [
        "# Parte Te√≥rica [12 puntos]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApXKwPDmxcEV"
      },
      "source": [
        "1. Explique cu√°l es la diferencia entre los datos de entrenamiento y validaci√≥n. [1 punto]\n",
        "\n",
        "2. Explique cu√°l es el principal desaf√≠o al trabajar problemas de clasificaci√≥n con data no supervisada. [1 punto]\n",
        "\n",
        "3. Explique en **sus palabras** qu√© es la matriz de confusi√≥n y para qu√© se utiliza. [1 puntos]\n",
        "\n",
        "4. Escriba la f√≥rmula de las siguientes m√©tricas y explique con **sus palabras** c√≥mo se interpretan. [1 punto cada uno]\n",
        "\n",
        "  * Accuracy\n",
        "  * Precision\n",
        "  * Recall\n",
        "  * F1 score\n",
        "\n",
        "5. Explique qu√© m√©trica recomendar√≠a para los siguientes contextos de clasificaci√≥n. [1 punto cada uno]\n",
        "\n",
        "  * Mantenimiento predictivo de fallas de maquinaria pesada en la industria minera.  \n",
        "  * Detecci√≥n de enfermedades altamente contagiosas.\n",
        "  * Aprobaci√≥n de cr√©ditos de alto riesgo.\n",
        "  * Detecci√≥n de cr√≠menes.\n",
        "\n",
        "6. Explique qu√© es la calibraci√≥n de modelos y para qu√© se usa. [1 punto]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy4QMWD8-FPk"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYFdD1aK-ICa"
      },
      "source": [
        "*Escriba su respuesta aqu√≠*\n",
        "\n",
        "P1: Los datos de entrenamiento son la informaci√≥n que se utiliza para ajustar los par√°metros del modelo y se utilizan para aprender patrones a partir de ejemplos etiquetados. Los datos de validaci√≥n son informaci√≥n que se guarda para permanecer al margen del entrenamiento y que son los que se utilizan para las decisiones de modelado que se toman sin sesgo, como pueden ser: seleccionar hiperpar√°metros, escoger el umbral de la decisi√≥n, comparar algoritmos, detectar sobreajuste.\n",
        "\n",
        "P2: El principal desaf√≠o de trabajar problemas de clasificaci√≥n con data no supervisada es que no existe una \"verdad\" de referencia, debido a que es necesario elegir grupos o forma de las particiones sin conocer la forma y sin saber si realemente se corresponde a las clases \"reales\", de esta forma los clusters pueden no alinearse a las categor√≠as relevantes. Adem√°s su evaluaci√≥n es imprecisa, pues se utilizan medidas internas como la silueta.\n",
        "\n",
        "P3: La matriz de confusi√≥n es una representaci√≥n tabular que sintetiza, por cada clase, las predicciones que el modelo realiza correctamente y las predicciones que efect√∫a err√≥neamente: Verdaderos Positivos (TP), Falsos Positivos (FP), Verdaderos Negativos (TN), y Falsos Negativos (FN). La matriz de confusi√≥n permite determinar cu√°l es el tipo de error m√°s cometido por el modelo, permite calcular m√©tricas derivadas de la matriz de confusi√≥n, como la precision, el recall, el F1 score, especificidad, y permite ajustar umbrales y costes en funci√≥n de la criticidad de FP y FN.\n",
        "\n",
        "\n",
        "P4:\n",
        "- Accuracy: (TP + TN) / (TP + TN + FP + FN), es la proporci√≥n de aciertos globales, sin embargo, con clases desbalanceadas, debido a que un modelo que predice siempre la clase mayoritaria obtiene un accuracy alta. Mientras m√°s alta sea la accuracy es mejor, en caso de clases balanceadas, si no lo est√°, no sirve tanto ya que puede ser enga√±osa. Sensible al umbral.\n",
        "\n",
        "- Precision: (TP / TP + FP), es la correcta predicci√≥n de predicciones positivas, cuantas son correctas, alta precisi√≥n implica pocos falsos positivos. Se utiliza cuando los falsos positivos son costosos, al aumentar el recall puede bajar y es sensible al umbral. Reportar macro recall si hay desbalance\n",
        "\n",
        "- Recall: (TP / (TP + FN), se preocupa de los positivos reales, revisa cuantos detecta el modelo. Un alto recall indica que se cuentan con pocos falsos negativos. Util en medicina, donde es muy costoso tener un falso negativo, por ejemplo en cancer. Es sensible al umbral, donde mover el umbral hacia abajo puede subir el recal. Reportar macro recall si hay desbalance\n",
        "\n",
        "- F1 Score: 2 * (Precision * recall / (precision + recall), es la media arm√≥nica entre precisi√≥n y recall, es √∫til cuando se necesita equilibrar ambas clases y hay desbalance. Evita falsos positivos y falsos negativos, sin embargo, al no incorporar los verdaderos negativos, puede ignorar la clase mayoritaria.\n",
        "\n",
        "P5:\n",
        "\n",
        "- Mantenimiento predictivo de fallas de maquinaria pesada en la industria minera: Recall, ya que perder una falla implica grandes costos, como puede ser un accidente o maquinaria sin poder utilizarce y perder dinero o tiempo.\n",
        "\n",
        "- Detecci√≥n de enfermedades altamente contagiosas: Recall, ya que omitir un falso negaetivo es muy costoso, ya que decirle a una persona que no tiene cancer cuando en verdad si lo tiene. Es mejor decir que si tenia cancer y hacerle m√°s estudios y descartarlo despu√©s a decirle que no ten√≠a\n",
        "\n",
        "- Aprobaci√≥n de cr√©ditos de alto riesgo: Si lo que se busca es aprobar cr√©ditos, se recomienda utilizar precision de ‚Äúaprobar‚Äù, ya que se minimizan los falsos positivos, es decir, que se minimiza aprobar a quien no pagar√°.\n",
        "Si lo que es positivo es si ser√° moroso, se prioriza Recall de ‚Äúmoroso‚Äù, ya que se minimizan los falsos negativos, ya que es importante conceder a quien no pagar√°.\n",
        "\n",
        "- Detecci√≥n de cr√≠menes: Recall, con esto se reducen los falso negativos o no detectar un crimen, nuevamente debido a lo complejo de no detectarlo. Es mejor equivocarse diciendo que si era y que realmente no lo era.\n",
        "\n",
        "P6: La calibraci√≥n de modelos ajusta las probabilidades predichas para que reflejen las frecuencias reales de los datos. Se utiliza para tomar desiciones basadas en las probabilidades, donde por ejemplo, es posible fijar umbrales coherentes con la data y priorizar, tener una mayor confianza en lo que se est√° haciendo, adem√°s para combinar modelos y mejorar interpretabilidad de los usuarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg_9jBqtgRDO"
      },
      "source": [
        "# Parte pr√°ctica [48 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slm6yRfdfZwS"
      },
      "source": [
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1BnO4tyh3vM2P199Ec9s3JjngQ4qQ9seP\"\n",
        "\" width=\"300\">\n",
        "</p>\n",
        "\n",
        "\n",
        "Tras el tr√°gico despido de la m√≠tica mascota de Maip√∫, Renac√≠n decide adentrarse como consultor en el mercado futbolero, el cu√°l (para variar...) est√° cargado en especulaciones.\n",
        "\n",
        "Como su principal tarea ser√° asesorar a los directivos de los clubes sobre cu√°l jugador comprar y cu√°l no, Renac√≠n desea generar modelos predictivos que evalu√©n distintas caracter√≠sticas de los jugadores; todo con el fin de tomar decisiones concretas basadas en los datos.\n",
        "\n",
        "Sin embargo, su condici√≥n de corporeo le impidi√≥ tomar la versi√≥n anterior de MDS7202, por lo que este motivo Renac√≠n contrata a su equipo para lograr su objetivo final. Dado que a√∫n tiene fuertes v√≠nculos con la direcci√≥n de deportes de la municipalidad, el corporeo le entrega base de datos con las estad√≠sticas de cada jugador para que su equipo empieze a trabajar ya con un dataset listo para ser usado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnbx7RwHfkue"
      },
      "source": [
        "**Los Datos**\n",
        "\n",
        "Para este laboratorio deber√°n trabajar con el csv `statsplayers.csv`, donde deber√°n aplicar algoritmos de aprendizaje supervisado de clasificaci√≥n en base a caracter√≠sticas que describen de jugadores de f√∫tbol.\n",
        "\n",
        "Para comenzar cargue el dataset se√±alado y a continuaci√≥n vea el reporte **`Player_Stats_Report.html`** (adjunto en la carpeta del enunciado) que describe las caracter√≠sticas principales del `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mX6iwOWUfrp_"
      },
      "outputs": [],
      "source": [
        "## Si usted est√° utilizando Colabolatory le puede ser √∫til este c√≥digo para cargar los archivos.\n",
        "#try:\n",
        "#    from google.colab import drive\n",
        "#    drive.mount(\"/content/drive\")\n",
        "#    path = 'Direcci√≥n donde tiene los archivos en el Drive'\n",
        "#except:\n",
        "#    print('Ignorando conexi√≥n drive-colab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bxm1b8txzxMC"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1encW_P7zQHC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, classification_report, confusion_matrix, f1_score)\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXMCHC79zoEh"
      },
      "outputs": [],
      "source": [
        "# Carga de datos\n",
        "# Subir archivo para colab\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Cargar los archivos\n",
        "df = pd.read_csv(\"stats_players.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdcucZhp-M_0"
      },
      "source": [
        "## 1. Predicci√≥n de Seleccionados Nacionales [14 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXrewqxjjzvA"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://www.futuro.cl/wp-content/uploads/2016/06/chile-argentina-meme-12.jpg\" width=\"300\">\n",
        "</p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfre1YsSDqla"
      },
      "source": [
        "### 1.1 Preprocesamiento [5 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR00u4HTDtxv"
      },
      "source": [
        "Tareas:\n",
        "\n",
        "1. Genere los labels para la clasificaci√≥n binaria en una variable llamada `label`. Para esto, trabaje sobre el atributo `National_Position` suponiendo que los valores nulos son jugadores no seleccionados para representar a su pa√≠s. [Sin puntaje]\n",
        "\n",
        "2. Hecho esto, ¬øcu√°ntos se tienen ejemplos por cada clase? Comente lo que observa. [1 punto]\n",
        "\n",
        "3. Genere un `ColumnTransformer` en donde especifique las transformaciones que hay que realizar para cada columna (por ejemplo StandarScaler, MinMaxScaler, OneHotEncoder, etc...) para que puedan ser utilizadas correctamente por el modelo predictivo y gu√°rdelo una variable llamada `col_transformer`. [2 puntos]\n",
        "\n",
        "4. Comente y justifique las transformaciones elegidas sobre cada una de las variables (para esto utilice el material `Player_Stats_Report.html` que viene en el zip del lab), al igual que las transformaciones aplicadas. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgAk0kbPjEsx"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhC2sZj9dSI1"
      },
      "outputs": [],
      "source": [
        "#Se genera label sobre el atributo National_Position, suponiendo que los valores nulos son jugadores no seleccionados para representar a su pa√≠s\n",
        "df['label'] = df['National_Position'].apply(lambda x: 0 if pd.isna(x) else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f512c70d"
      },
      "outputs": [],
      "source": [
        "display(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiHAYaLB1KbV"
      },
      "source": [
        "Label tiene una gran cantidad de datos, es decir, asumiendo que son jugadores que no se han llamado a la selecci√≥n, solo un 6.5% de los jugadores son llamados a jugar por su seleccion  (solo 1075 jugadores, de un total de 16513), lo que es un n√∫mero peque√±o, pero realista, asumiendo el nivel competitivo del deporte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d3d09a8"
      },
      "outputs": [],
      "source": [
        "# Definir las transformaciones para cada tipo de columna\n",
        "# Caracter√≠sticas num√©ricas: StandardScaler\n",
        "# Caracter√≠sticas categ√≥ricas: OneHotEncoder\n",
        "\n",
        "# Identificar columnas num√©ricas y categ√≥ricas (excluyendo 'label' y 'National_Position')\n",
        "columnas_numericas = df.select_dtypes(include=np.number).columns.tolist()\n",
        "columnas_numericas.remove('label')\n",
        "\n",
        "columnas_categoricas = df.select_dtypes(include='object').columns.tolist()\n",
        "columnas_categoricas.remove('Name')\n",
        "columnas_categoricas.remove('Nationality')\n",
        "columnas_categoricas.remove('Club_Position') # Club_Position se usar√° en la parte 2\n",
        "columnas_categoricas.remove('National_Position')\n",
        "\n",
        "# Crear el ColumnTransformer\n",
        "col_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), columnas_numericas), # Usando StandardScaler para caracter√≠sticas num√©ricas\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), columnas_categoricas) # Usando OneHotEncoder para caracter√≠sticas categ√≥ricas\n",
        "    ],\n",
        "    remainder='passthrough' # Mantener otras columnas para uso posterior\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3T6SxtPLD8e"
      },
      "source": [
        "En un principio se identifican los atributos numericos, por otro lado las categ√≥ricas. Para las variables num√©ricas se decidi√≥ aplicar StandardScaler, ya que centra cada caracter√≠stica en media cero y la escala a una desviaci√≥n est√°ndar unitaria. Ya que con esto se puede trabajar con los datos a una misma escala. Para las categ√≥ricas, se eligi√≥ el OneHotEncoder con el par√°metro handle_unknown='ignore'. Esto convierte cada categor√≠a en una representaci√≥n binaria sin imponer un orden artificial y, al mismo tiempo, evita errores si durante la fase de prueba aparecen categor√≠as nuevas no vistas en el entrenamiento.\n",
        "\n",
        "La variable label se mantuvo fuera porque corresponde al objetivo del modelo y procesarla junto con las caracter√≠sticas producir√≠a data leakage.\n",
        "\n",
        "La columna Name se descart√≥ debido a su alta cardinalidad y su car√°cter de identificador √∫nico, que no aporta informaci√≥n generalizable y solo incrementar√≠a la dimensionalidad al utilizar OneHotEncoder. Lo mismo sucede con Nationality, que posee m√°s de 160 nacionalidades distintas.\n",
        "\n",
        "La variable Club_Position no se modific√≥ debido a que despu√©s se realiza un tratamiento distinto.\n",
        "\n",
        "National_Position se elimina debido a que contiene una gran cantidad de datos faltantes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv1HOfcNEPF4"
      },
      "source": [
        "### 1.2 Entrenamiento [3 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPkuXTUBvB0"
      },
      "source": [
        "Ahora, vamos a entrenar los pipelines generados en los pasos anteriores. Para esto, debe realizar las siguientes tareas:\n",
        "\n",
        "1. Separe los datos de entrenamiento en un conjunto de entrenamiento y de prueba  (la proporci√≥n queda a su juicio). En este paso, seleccione los ejemplos de forma aleatoria e intente mantener la distribuci√≥n original de labels de cada clase en los conjuntos de prueba/entrenamiento. (vea la documentaci√≥n de `train_test_split`). [1 puntos]\n",
        "\n",
        "\n",
        "2. Defina un pipeline llamado `pipeline_xgboost` y otro llamado `pipeline_lightgbm`. Estos pipelines deben tener el mismo ColumnTransformer definido en la secci√≥n de preprocesamiento, pero deben variar los clasificadores de acuerdo al nombre de cada pipeline. [1 puntos]\n",
        "\n",
        "3. Entrene los pipelines. [1 punto]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbadONFtjGnE"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLtlXGTPdWAV"
      },
      "outputs": [],
      "source": [
        "#Armar el set de num√©ricas + categ√≥ricas, adem√°s de agregar 'Club_Position'\n",
        "feature_cols = columnas_numericas + columnas_categoricas\n",
        "X = df[feature_cols].copy()\n",
        "y = df['label'].copy()\n",
        "\n",
        "# 2) Split estratificado para mantener proporci√≥n de clases\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"Tama√±o train:\", X_train.shape, \"| Tama√±o test:\", X_test.shape)\n",
        "print(\"Distribuci√≥n train:\\n\", y_train.value_counts(normalize=True))\n",
        "print(\"Distribuci√≥n test:\\n\", y_test.value_counts(normalize=True))\n",
        "print(\"Ojo, el 35 son las columnas de cada subdf\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wYJ8Y17bX8a"
      },
      "outputs": [],
      "source": [
        "# Calcular ratio en el set de entrenamiento\n",
        "n_pos = y_train.sum()\n",
        "n_neg = len(y_train) - n_pos\n",
        "ratio = n_neg / n_pos\n",
        "ratio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2Fv_uh1btHz"
      },
      "source": [
        "Se da cuenta que se cuenta con data desbalanceada, por lo que se le asignar√°n los pesos calculados anteriormente\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5gJTF58aHuD"
      },
      "outputs": [],
      "source": [
        "# Pipeline con XGBoost\n",
        "pipeline_xgboost = Pipeline(steps=[\n",
        "    ('prep', col_transformer),\n",
        "    ('model', XGBClassifier(\n",
        "        n_estimators=300,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=6,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        eval_metric='logloss',\n",
        "        scale_pos_weight=ratio #ratio calculado anteriormente\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Pipeline con LightGBM\n",
        "pipeline_lightgbm = Pipeline(steps=[\n",
        "    ('prep', col_transformer),\n",
        "    ('model', LGBMClassifier(\n",
        "        n_estimators=300,\n",
        "        learning_rate=0.1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        is_unbalance=True,\n",
        "        verbose=-1\n",
        "    ))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAU3F3H2ariF"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento\n",
        "pipeline_xgboost.fit(X_train, y_train)\n",
        "pipeline_lightgbm.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poc9HSNBFeKO"
      },
      "source": [
        "### 1.3 Resultados [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGGCj8YtFil1"
      },
      "source": [
        "1. Calcule las m√©tricas accuracy, precisi√≥n y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) para evaluar el rendimiento de los distintos modelos. Verifique sus resultados usando `classification_report`. [2 puntos]\n",
        "\n",
        "2. Explique qu√© implican los valores de accuracy, precisi√≥n y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) y c√≥mo influye la cantidad de ejemplos por clase en los resultados obtenidos. [2 puntos]\n",
        "\n",
        "3. Explique qu√© m√©trica le parece m√°s adecuada y concluya qu√© modelo tiene un mejor desempe√±o. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1hkVFdujJTi"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNmI_tbbdQte"
      },
      "outputs": [],
      "source": [
        "def evaluar_modelo(nombre, pipeline, X_test, y_test):\n",
        "    # Predicci√≥n con el pipeline\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    # M√©tricas solicitadas (clase positiva = 1)\n",
        "    acc  = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
        "    rec  = recall_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
        "\n",
        "    print(f\"{nombre}\")\n",
        "    print(f\"Accuracy:  {acc:.4f}\")\n",
        "    print(f\"Precisi√≥n (clase 1): {prec:.4f}\")\n",
        "    print(f\"Recall    (clase 1): {rec:.4f}\\n\")\n",
        "\n",
        "    # Verificaci√≥n con classification_report\n",
        "    print(\"Reporte de clasificacion:\")\n",
        "    print(classification_report(y_test, y_pred, digits=3))\n",
        "    print(\"Matriz de confusi√≥n:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(\"-\"*50, \"\\n\")\n",
        "\n",
        "# Evaluar ambos modelos\n",
        "evaluar_modelo(\"XGBoost\",  pipeline_xgboost,  X_test, y_test)\n",
        "evaluar_modelo(\"LightGBM\", pipeline_lightgbm, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RAwOKsSSh1E"
      },
      "source": [
        "Para poder realizar de manera correcta el entrenamiento, es que se le ha cambiado la proporci√≥n a XGBoost, para intentar manejar el desbalance de clases positivas versus negativas, adem√°s de agregarle         is_unbalance=True al segundo modelo, ajustando el umbral de decisi√≥n de validaci√≥n, sin embargo, los resultados muestran el efecto de trabajar con la variable objetivo desbalanceada.\n",
        "\n",
        "Accuracy, o exactitud, es la proporci√≥n de aciertos (TP+TN)/Total, se mantiene alta porque est√° dominada por los verdaderos negativos de la clase mayoritaria, aun corrigiendo el desbalance en el entrenamiento, sigue reflejando principalmente el buen desempe√±o sobre los ‚Äúno seleccionados‚Äù y por s√≠ sola no captura la capacidad del modelo para encontrar la clase positiva.\n",
        "\n",
        "La exactitud indica que tan correctas son las predicciones (TP/(TP+FP), donde al cambiar el umbral para aumentar cobertura, la precisi√≥n tiende a descender debido a que aceptamos m√°s falsos positivos.\n",
        "\n",
        "El Recall mide la cobertura sobre los verdaderos seleccionados, en donde esta es la medida m√°s sensible al desbalance, debido a que con pocos ejemplos, se dejan escapar los falsos negativos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9SqVrWdX7ng"
      },
      "source": [
        "\n",
        "Debido al claro desbalance, es que las m√©tricas no son suficientes para poder predecir de manera correcta, sin embargo, el modelo que presenta el mejor equilibrio entre desempe√±o global y capacidad de detecci√≥n de la clase positiva es LightGBM. En particular, mantiene una accuracy comparable a XGBoost (‚âà0,928 frente a ‚âà0,925), pero lo supera en los otros indicadores para el objetivo del estudio, posee una precisi√≥n de la clase positiva superior (‚âà0,385 vs. ‚âà0,350) y un recall tambi√©n mayor (‚âà0,288 vs. ‚âà0,265), lo que implica identificar una mayor proporci√≥n de jugadores efectivamente seleccionados con menor proporci√≥n de falsos positivos que su contraparte. Dado el desbalance entre clases, el accuracy puede no ser la mejor opci√≥n, la combinaci√≥n de mayor recall con una precisi√≥n no disminuida confirma que LightGBM ofrece la mejor relaci√≥n se√±al-ruido sobre la clase de inter√©s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy5VMU6ae_g6"
      },
      "source": [
        "## 2. Predicci√≥n de posiciones de jugadores [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0PGg_hLgr4H"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://pbs.twimg.com/media/E1rfA1aWEAYU6Ny.jpg\" width=\"300\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6rSnAesfOm3"
      },
      "source": [
        "En una nueva jornada de desmesuradas transacciones deportivas, Renac√≠n escuch√≥ a sus colegas discutir acerca de que el precio de cada jugador depende en gran medida de la posici√≥n en la cancha en la que juega. Y adem√°s, que hay bastantes jugadores nuevos que no tienen muy claro en que posici√≥n verdaderamente brillar√≠an, por lo que actualmente puede que actualmente est√©n jugando en posiciones sub-optimas.\n",
        "\n",
        "Viendo que los resultados del primer an√°lisis no son tan esperanzadores, el corporeo los comanda a cambiar su tarea: ahora, les solicita que construyan un clasificador enfocado en predecir la mejor posici√≥n de los jugadores en la cancha seg√∫n sus caracter√≠sticas.\n",
        "\n",
        "Para lograr esto, primero, les pide que etiqueten de la siguiente manera los valores que aparecen en el atributo `Club_Position`, pidiendo que agrupen los valores en los siguientes grupos:\n",
        "\n",
        "**Nota**:  Renac√≠n les recalca que **no deben utilizar los valores ```Sub``` y ```Res``` de esta columna**.\n",
        "\n",
        "```python\n",
        "ataque = ['ST', 'CF']\n",
        "central_ataque = ['RW', 'CAM', 'LW']\n",
        "central = ['RM', 'CM', 'LM']\n",
        "central_defensa = ['RWB', 'CDM', 'LWB']\n",
        "defensa = ['RB', 'CB', 'LB']\n",
        "arquero = ['GK']\n",
        "```\n",
        "\n",
        "La elecci√≥n del clasificador se justificar en base a la siguiente [gu√≠a](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) y se deben comentar los resultados obtenidos en la clasificaci√≥n.\n",
        "\n",
        "**Tareas:** [1 punto por tarea]\n",
        "\n",
        "1. En un nuevo dataframe, aplique las etiquetas descritas anteriormente en cada uno de los valores se√±alados en esta secci√≥n y gu√°rdelos en la variable `label`.\n",
        "2. Cuente cu√°ntos por clase quedan.\n",
        "3. Entrene el nuevo pipeline y ejecute una evaluaci√≥n de este.  \n",
        "4. Comente los resultados obtenidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBmSaWh8i2MI"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir_7zMh2i1vg"
      },
      "outputs": [],
      "source": [
        "# Creamos un nuevo data frame\n",
        "df_pos = df.copy()\n",
        "\n",
        "# Cramos lo solicitado seg√∫n atributos\n",
        "grupo_map = {\n",
        "    'ataque': {'ST', 'CF'},\n",
        "    'central_ataque': {'RW', 'CAM', 'LW'},\n",
        "    'central': {'RM', 'CM', 'LM'},\n",
        "    'central_defensa': {'RWB', 'CDM', 'LWB'},\n",
        "    'defensa': {'RB', 'CB', 'LB'},\n",
        "    'arquero': {'GK'}\n",
        "}\n",
        "\n",
        "# se eliminan \"sub\" y \"res\"\n",
        "mask_valid = df_pos['Club_Position'].notna() & (~df_pos['Club_Position'].isin(['Sub', 'Res']))\n",
        "df_pos = df_pos.loc[mask_valid].copy()\n",
        "\n",
        "# Funci√≥n de mapeo\n",
        "def map_pos(value: str) -> str:\n",
        "    for g, posiciones in grupo_map.items():\n",
        "        if value in posiciones:\n",
        "            return g\n",
        "    return np.nan\n",
        "\n",
        "df_pos['label'] = df_pos['Club_Position'].apply(map_pos)\n",
        "\n",
        "# Contamos por clase para revisar no tener el mismo error de antes\n",
        "print(\"Conteo por clase (label):\")\n",
        "print(df_pos['label'].value_counts())\n",
        "print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC5C-mwBgCxc"
      },
      "outputs": [],
      "source": [
        "# Definir columnas, al igual que lo hicimos anteriormente, excluimos lo que no no queremos que est√© en el modelo\n",
        "\n",
        "columnas_numericas_pos = df_pos.select_dtypes(include=np.number).columns.tolist()\n",
        "if 'label' in columnas_numericas_pos:\n",
        "    columnas_numericas_pos.remove('label')\n",
        "\n",
        "columnas_categoricas_pos = df_pos.select_dtypes(include='object').columns.tolist()\n",
        "for col_drop in ['label', 'Club_Position', 'National_Position', 'Name', 'Nationality']:\n",
        "    if col_drop in columnas_categoricas_pos:\n",
        "        columnas_categoricas_pos.remove(col_drop)\n",
        "\n",
        "#Creamos el column transformer pero ahora para posicion\n",
        "col_transformer_pos = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), columnas_numericas_pos),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), columnas_categoricas_pos),\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# Preparar X, y y split multiclase\n",
        "X_pos = df_pos.drop(columns=['label', 'Club_Position', 'National_Position', 'Name', 'Nationality'], errors='ignore')\n",
        "y_pos = df_pos['label'].astype('category')\n",
        "\n",
        "# Eliminar filas con NaN en 'label' antes de dividir los datos\n",
        "df_pos_cleaned = df_pos.dropna(subset=['label']).copy()\n",
        "X_pos_cleaned = df_pos_cleaned.drop(columns=['label', 'Club_Position', 'National_Position', 'Name', 'Nationality'], errors='ignore')\n",
        "y_pos_cleaned = df_pos_cleaned['label'].astype('category')\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_pos_cleaned, y_pos_cleaned, test_size=0.2, random_state=42, stratify=y_pos_cleaned\n",
        ")\n",
        "\n",
        "# Definir el pipeline para LogisticRegression multinomial\n",
        "pipeline_pos = Pipeline(steps=[\n",
        "    ('prep', col_transformer_pos),\n",
        "    ('model', LogisticRegression(\n",
        "        solver='saga',\n",
        "        max_iter=2000, n_jobs=-1, random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Entrenar modelo\n",
        "pipeline_pos.fit(X_train, y_train)\n",
        "\n",
        "# Evaluar modelos\n",
        "y_pred = pipeline_pos.predict(X_test)\n",
        "\n",
        "acc  = accuracy_score(y_test, y_pred)\n",
        "f1m  = f1_score(y_test, y_pred, average='macro')  # macro-F1: justo con clases desbalanceadas\n",
        "print(f\"Accuracy:  {acc:.4f}\")\n",
        "print(f\"Macro-F1:  {f1m:.4f}\\n\")\n",
        "\n",
        "print(\"Reporte de clasificaci√≥n:\")\n",
        "print(classification_report(y_test, y_pred, target_names=sorted(y_pos_cleaned.unique().tolist()), digits=3))\n",
        "\n",
        "print(\"Matriz de confusi√≥n (orden etiquetas):\", sorted(y_pos_cleaned.unique().tolist()))\n",
        "print(confusion_matrix(y_test, y_pred, labels=sorted(y_pos_cleaned.unique().tolist())))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObO4O9jaoJHj"
      },
      "source": [
        "Notamos el modelo es aceptable (accuracy = 0,745) y razonable en t√©rminos de equilibrio entre clases (macro-F1 = 0,663), sin embargo, la matriz de confusi√≥n y los indicadores por clase evidencian diferencias marcadas de dificultad seg√∫n la posici√≥n.\n",
        "\n",
        "\n",
        "Los roles extremos se distinguen de manera correctar (GK, defensa, ataque), sin embargo, le cuesta separar sub-roles del mediocampo, donde el perfil de atributos es m√°s parecido y las etiquetas agregadas introducen zonas lim√≠trofes.\n",
        "Las clases arquero y defensa son las m√°s separables, arquero alcanza un desempe√±o perfecto (P=R=F1=1,00), consistente con atributos muy distintivos del puesto, y defensa logra resultados altos (P=0,834; R=0,958; F1=0,892), lo que sugiere que el modelo capta bien los rasgos defensivos. ataque tambi√©n presenta un rendimiento s√≥lido (F1=0,813) con buen recall (0,860). En contraste, las clases del medio muestran mayor solapamiento, donde central queda en un nivel intermedio (F1=0,597) y central_ataque (F1=0,418; R=0,362) y central_defensa (F1=0,258; R=0,190) exhiben el peor comportamiento. La confusi√≥n se concentra, principalmente, en central_ataque que es reconocido como central (56 casos) y central_defensa como defensa (22 casos), adem√°s de desv√≠os de central a central_ataque (36) y central a defensa (20). De esta forma, se nota que los roles contiguos no est√°n suficientemente separadas por las variables actuales o requieren relaciones no lineales para ser captadas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bL2m8nNojXM"
      },
      "source": [
        "## 3. Predicciones de Seleccionados Nacionales para el Jere Klein [30 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2XmRsJdsEh_"
      },
      "source": [
        "<center>\n",
        "<img src='https://www.radioactiva.cl/wp-content/uploads/2024/04/Jere-Klein-1-768x432.webp' width=500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgmUoVDsqUPu"
      },
      "source": [
        "Despu√©s de alcanzar la fama como cantante urbano, Jere Klein decide explorar una nueva faceta. Con su amor por el f√∫tbol y convencido de que los artistas urbanos poseen un talento y versatilidad excepcionales, Jere se embarca en un proyecto innovador: desarrollar un sistema de inteligencia artificial capaz de identificar a jugadores que tienen potencial para convertirse en futbolistas profesionales. Su teor√≠a es que muchos artistas del g√©nero urbano chileno, con sus habilidades √∫nicas y su disciplina, podr√≠an destacarse tambi√©n en el deporte. Con este sistema, Jere espera no solo abrir nuevas oportunidades para sus colegas artistas, sino tambi√©n demostrar la amplia gama de talentos que pueden ofrecer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD8pQ5Zfq8dE"
      },
      "source": [
        "### 2.1 ¬øQu√© modelo de √°rbol es m√°s de \"pana\"? [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB-KUA4g99eo"
      },
      "source": [
        "<center>\n",
        "<img src='https://64.media.tumblr.com/39189215a7d3d96823cb359f35b44e05/tumblr_psmrhrR3Xw1qf5hjqo4_540.gif' width=300 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL-moVhB9vPH"
      },
      "source": [
        "\n",
        "**Tareas**\n",
        "\n",
        "\n",
        "1. Considerando el la variable llamada `label` creada en la secci√≥n 1.1. Para determinar cu√°l modelo de √°rbol ser√≠a m√°s adecuado para la tarea en cuesti√≥n, utilice PyCaret. Este deber√° centrarse exclusivamente en modelos de tipo √°rbol. Jere ha especificado que busca un modelo que tome decisiones r√°pidamente y que tenga una baja tasa de falsos positivos, ya que planea invertir en estos jugadores. [3 puntos]\n",
        "\n",
        "Para la comparaci√≥n, utilice los siguientes modelos:\n",
        "\n",
        "```python\n",
        "['et', 'rf', 'dt', 'xgboost', 'lightgbm', 'catboost']\n",
        "```\n",
        "\n",
        "2. Explique en brevemente que son los modelos de la siguiente lista `['et', 'rf', 'dt']` y como funcionan. [3 punto]\n",
        "\n",
        "3. Tras realizar la comparaci√≥n de modelos, seleccione aquel que muestre el mejor rendimiento en t√©rminos de velocidad y precisi√≥n, especialmente en la reducci√≥n de falsos positivos. Utilice la funci√≥n `evaluate_model` de PyCaret para revisar y analizar los resultados obtenidos en los siguientes aspectos:\n",
        "\n",
        "  - **Confusi√≥n Matrix**: ¬øC√≥mo se encuentran la tasa de verdaderos positivos y verdaderos negativos?\n",
        "  - **Threshold**: ¬øEs acaso el umbral por defecto del modelo el mejor para las predicciones?\n",
        "  - **Feature Importance**: ¬øCu√°les son las variables con mejor desempe√±o? ¬øA qu√© podr√≠a deberse esto?\n",
        "  - **Learning Curve**: ¬øEl modelo presenta alg√∫n problema?\n",
        "\n",
        "  [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY85nrViYROF"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RIjaCrKbcSF"
      },
      "source": [
        "Explique en brevemente que son los modelos de la siguiente lista ['et', 'rf', 'dt'] y como funcionan.\n",
        "\n",
        "Los modelos de la lista son algoritmos basados en √°rboles de decisi√≥n que se utilizan para clasificaci√≥n y regresi√≥n.\n",
        "\n",
        "Extra Trees es un m√©todo de ensamble que crea varios √°rboles de decisi√≥n utilizando todo el conjunto de datos, pero introduce aleatoriedad en la forma en que selecciona los puntos de corte para dividir los nodo. A diferencia de Random Forest, no utiliza bootstrap y elige los umbrales de divisi√≥n de manera completamente aleatoria, lo que lo hace m√°s r√°pido de entrenar aunque potencialmente menos preciso. La predicci√≥n final se obtiene promediando las predicciones de todos los √°rboles.\n",
        "Random Forest tambi√©n es un m√©todo ensemble que construye m√∫ltiples √°rboles de decisi√≥n, pero lo hace creando muestras bootstrap del conjunto de datos original y seleccionando aleatoriamente un subconjunto de caracter√≠sticas en cada divisi√≥n. Cada √°rbol se entrena de forma independiente y la predicci√≥n final se determina por votaci√≥n mayoritaria en clasificaci√≥n o promedio en regresi√≥n. Este m√©todo es robusto frente al sobreajuste y generalmente ofrece un buen balance entre precisi√≥n y generalizaci√≥n.\n",
        "Decision Tree es un modelo individual que construye una estructura jer√°rquica de decisiones dividiendo repetidamente los datos seg√∫n las caracter√≠sticas que mejor separan las clases o minimizan el error. Comienza desde la ra√≠z y va creando ramas mediante preguntas binarias sobre las variables hasta llegar a las hojas que contienen las predicciones finales. Es muy interpretable y r√°pido, pero propenso al sobreajuste si no se controla su complejidad mediante poda o limitaci√≥n de profundidad.\n",
        "\n",
        "A la hora de comentar sobre cuando se usa cada uno, et es ideal cuando se necesita entrenar modelos r√°pidamente y hacer predicciones veloces, especialmente con grandes conjuntos de datos. Es √∫til para reducir el sobreajuste, manejar muchas caracter√≠sticas y trabajar con datos ruidosos.\n",
        "\n",
        "Random Forest es una opci√≥n vers√°til y equilibrada. Funciona bien en la mayor√≠a de los casos sin requerir muchos ajustes, y es √∫til para medir la importancia de las caracter√≠sticas. Es la opci√≥n m√°s segura al comenzar un proyecto pero un poquito lenta.\n",
        "\n",
        "Decision Tree es adecuado para modelos simples e interpretables, especialmente cuando la transparencia es crucial. Es ideal para conjuntos de datos peque√±os y cuando se requiere velocidad en las predicciones, pero hay que tener cuidado con el sobreajuste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vd6irKznkQI9",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!python --version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoasU6pOH_Jw",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install pycaret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDXZrvX5JEGB",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QScw8veXJSOu"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "print(mlflow.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUCjOjsEYUXL"
      },
      "outputs": [],
      "source": [
        "from pycaret.datasets import get_data\n",
        "from pycaret.classification import *\n",
        "import os\n",
        "\n",
        "os.environ[\"PYCARET_CUSTOM_LOGGING_LEVEL\"] = \"CRITICAL\"\n",
        "\n",
        "# Continuar c√≥digo aqu√≠\n",
        "\n",
        "data_pycaret = df.copy()\n",
        "\n",
        "# en vscode usar venv, en colab correr tal cual est√°\n",
        "clf1 = setup(data = data_pycaret, target = 'label', session_id = 42,\n",
        "            ignore_features = ['Name', 'Nationality', 'Club_Position', 'National_Position'],\n",
        "            fix_imbalance = True,\n",
        "            log_experiment=False,\n",
        "            experiment_name='national_selection_tree_models')\n",
        "\n",
        "\n",
        "best_model = compare_models(\n",
        "    include = ['et', 'rf', 'dt', 'xgboost', 'lightgbm'],\n",
        "    sort = 'Precision'\n",
        ")\n",
        "\n",
        "print(best_model)\n",
        "\n",
        "# evaluar el mejor modelo usando evaluate_model\n",
        "evaluate_model(best_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo a analizar es Extra Trees ya que tiene los mejores resultados. Despu√©s de compararl de modelos, Extra Trees demuestra ser la mejor opci√≥n considerando velocidad y precisi√≥n. Con un tiempo de entrenamiento destacado y una precisi√≥n de 0.2373 (la m√°s alta entre todos los modelos), es el modelo m√°s adecuado para minimizar falsos positivos en las decisiones de inversi√≥n de Jere ya que maximiza la precisi√≠on. Una precisi√≥n superior significa que cuando el modelo predice que un jugador ser√° seleccionado, existe mayor probabilidad de que esto sea correcto, reduciendo as√≠ las inversiones err√≥neas.\n",
        "Confusion Matrix\n",
        "\n",
        "La matriz de confusi√≥n revela un desempe√±o conservador pero efectivo. Con 4898 verdaderos negativos y 52 verdaderos positivos, el modelo identifica correctamente la mayor√≠a de los casos. Los 56 falsos positivos son relativamente bajos, lo cual es crucial para Jere ya que representa inversiones err√≥neas m√≠nimas. Sin embargo, los 271 falsos negativos indican que el modelo pierde oportunidades al no identificar algunos jugadores seleccionables. Este trade-off es aceptable dado el objetivo de reducir riesgos de inversi√≥n.\n",
        "\n",
        "Sobre el threeshold, podemos decir que el gr√°dfico muestra que el umbral por defecto de 0.57 no es √≥ptimo. La precisi√≥n alcanza su punto m√°ximo alrededor de 0.2, mientras que el F1 score se maximiza cerca de 0.6. Para el caso de Jere, aumentar el umbral a aproximadamente 0.65-0.70 ser√≠a beneficioso, sacrificando algo de recall pero ganando mayor precisi√≥n y reduciendo a√∫n m√°s los falsos positivos. Esto har√≠a las predicciones m√°s conservadoras y confiables para decisiones de inversi√≥n.\n",
        "\n",
        "Sobre la feature importance podemoss ver que las variables m√°s importantes son Balance, Sliding_Tackle, Heading y Finishing. Estas caracter√≠sticas f√≠sicas y t√©cnicas son fundamentales porque reflejan habilidades concretas que los seleccionadores nacionales valoran: equilibrio para mantener posesi√≥n, capacidad defensiva en tackles, juego a√©reo y definici√≥n. La predominancia de Balance sugiere que la versatilidad y estabilidad f√≠sica son cruciales en selecciones nacionales donde se requiere adaptabilidad a diferentes sistemas t√°cticos y contextos de juego de alta presi√≥n.\n",
        "\n",
        "Sobre la learning curve, podemos decir que la curva de aprendizaje muestra un comportamiento saludable del modelo. El training score se mantiene consistentemente en 1.0, mientras que el cross-validation score aumenta progresivamente desde 0.64 hasta estabilizarse cerca de 0.99 alrededor de las 14,000 instancias de entrenamiento. La brecha inicial entre ambas curvas es significativa pero se reduce considerablemente, indicando que el modelo inicialmente presentaba overfitting que se corrigi√≥ con m√°s datos. La convergencia de ambas curvas al final sugiere que el modelo ha alcanzado un buen equilibrio y que datos adicionales probablemente no mejorar√≠an sustancialmente el rendimiento."
      ],
      "metadata": {
        "id": "gYEUJgsAR0-V"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8DSS3u1xMpB"
      },
      "source": [
        "### 2.2 Reducci√≥n de dimensionalidad [14 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLu0543p876P"
      },
      "source": [
        "<center>\n",
        "<img src='https://i.kym-cdn.com/photos/images/original/002/258/560/668.gif' width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT-bxJ0txwNF"
      },
      "source": [
        "A pesar de los resultados obtenidos previamente, el manager de Jere ha solicitado el entrenamiento de un modelo de XGBoost utilizando los datos disponibles. Adem√°s, se debe proceder a realizar una reducci√≥n de dimensionalidad basada en la importancia de las caracter√≠sticas.\n",
        "\n",
        "Para llevar a cabo esta tarea:\n",
        "\n",
        "1. Inicie entrenando un modelo XGBoost con todas las caracter√≠sticas disponibles. [2 puntos]\n",
        "\n",
        "2. Una vez el modelo est√© entrenado, eval√∫e y clasifique las caracter√≠sticas seg√∫n su importancia de forma descendente. [2 puntos]\n",
        "\n",
        "3. Utilice esta clasificaci√≥n para ejecutar una b√∫squeda recursiva de eliminaci√≥n de caracter√≠sticas, eliminando progresivamente las menos importantes y evaluando el impacto en el desempe√±o del modelo hasta identificar las N caracter√≠sticas m√°s cr√≠ticas. [2 puntos]\n",
        "\n",
        "4. Con este conjunto reducido de caracter√≠sticas, entrene un nuevo modelo y eval√∫e su rendimiento. [2 puntos]\n",
        "\n",
        "5. Posteriormente, responda a las siguientes preguntas para una comprensi√≥n m√°s profunda de los cambios y beneficios:\n",
        "\n",
        "  - ¬øEl rendimiento del modelo con las caracter√≠sticas seleccionadas es similar al del modelo original? ¬øC√≥mo se comparan en t√©rminos de precisi√≥n y robustez? [2 puntos]\n",
        "  - ¬øCu√°les son los beneficios potenciales de eliminar variables del modelo? Considere factores como la simplificaci√≥n del modelo, reducci√≥n del tiempo de entrenamiento, y mejora en la capacidad de generalizaci√≥n. [2 puntos]\n",
        "  - Comente si el modelo con menor dimensionalidad es m√°s sencillo de explicar. Explique brevemente por qu√© la eliminaci√≥n de ciertas caracter√≠sticas puede facilitar la comprensi√≥n y la explicaci√≥n del comportamiento del modelo. [2 puntos]\n",
        "\n",
        "Notar que con esta metodologia buscamos encontrar un punto entermedio entre n√∫mero de festures y desempe√±o. por esto, si observa que al aumentar festires el aumento es despreciable, puede no considerar agregar m√°s features a su modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHfmK63TuDOS"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptvUNrC_rT-X"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "# Eliminar las columnas no deseadas\n",
        "X = df.drop(columns=['label', 'Name', 'Nationality', 'National_Position', 'Club_Position'])  # Removemos las columnas que no se usan\n",
        "y = df['label']\n",
        "\n",
        "# Dividir los datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Definir las columnas num√©ricas y categ√≥ricas\n",
        "columnas_categoricas = X.select_dtypes(include=['object']).columns.tolist()\n",
        "columnas_numericas = X.select_dtypes(exclude=['object']).columns.tolist()\n",
        "\n",
        "# Definir el preprocesamiento para las columnas categ√≥ricas (One-Hot Encoding)\n",
        "col_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(), columnas_categoricas),\n",
        "        ('num', 'passthrough', columnas_numericas)  # Las columnas num√©ricas no se transforman\n",
        "    ])\n",
        "\n",
        "# Transformar los datos de entrenamiento\n",
        "X_train_transformed = col_transformer.fit_transform(X_train)\n",
        "\n",
        "# Inicializar y entrenar el modelo XGBoost\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "# Entrenar el modelo con los datos transformados\n",
        "xgb_model.fit(X_train_transformed, y_train_encoded)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "X_test_transformed = col_transformer.transform(X_test)\n",
        "y_pred = xgb_model.predict(X_test_transformed)\n",
        "\n",
        "# Evaluaci√≥n del modelo con accuracy\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy del modelo: {accuracy}\")\n",
        "print(\"Reporte de clasificaci√≥n:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Obtener las importancias de las caracter√≠sticas\n",
        "ohe_feature_names = col_transformer.named_transformers_['cat'].get_feature_names_out(columnas_categoricas)\n",
        "all_feature_names = columnas_numericas + list(ohe_feature_names)\n",
        "\n",
        "# Crear un DataFrame con las importancias de las caracter√≠sticas\n",
        "feature_importances = pd.Series(xgb_model.feature_importances_, index=all_feature_names)\n",
        "\n",
        "# Ordenar las importancias de las caracter√≠sticas\n",
        "sorted_feature_importances = feature_importances.sort_values(ascending=False)\n",
        "\n",
        "# Mostrar las importancias de las caracter√≠sticas ordenadas\n",
        "print(\"\\nImportancia de las caracter√≠sticas (descendente):\")\n",
        "display(sorted_feature_importances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mb9qjhohsTVu"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "# Aplicamos la eliminaci√≥n recursiva de caracter√≠sticas con validaci√≥n cruzada\n",
        "selector = RFECV(\n",
        "    estimator=xgb_model,\n",
        "    step=1,\n",
        "    cv=StratifiedKFold(5),\n",
        "    scoring='accuracy'\n",
        ")\n",
        "\n",
        "# Aplicar sobre los datos de entrenamiento transformados\n",
        "selector = selector.fit(X_train_transformed, y_train_encoded)\n",
        "\n",
        "# Mostrar el n√∫mero de caracter√≠sticas seleccionadas y el ranking\n",
        "print(f\"N√∫mero de caracter√≠sticas seleccionadas: {selector.n_features_}\")\n",
        "print(f\"Ranking de las caracter√≠sticas: {selector.ranking_}\")\n",
        "\n",
        "# Obtener las caracter√≠sticas seleccionadas (las que tienen un ranking de 1)\n",
        "selected_features = [all_feature_names[i] for i in range(len(all_feature_names)) if selector.support_[i]]\n",
        "\n",
        "print(\"\\nCaracter√≠sticas seleccionadas (m√°s cr√≠ticas):\")\n",
        "print(selected_features)\n",
        "\n",
        "# Realizamos predicciones con las caracter√≠sticas seleccionadas\n",
        "X_train_selected = X_train_transformed[:, selector.support_]\n",
        "X_test_selected = X_test_transformed[:, selector.support_]\n",
        "\n",
        "# Entrenar el modelo con las caracter√≠sticas seleccionadas\n",
        "xgb_model.fit(X_train_selected, y_train_encoded)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = xgb_model.predict(X_test_selected)\n",
        "\n",
        "# Evaluar el modelo con accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy del modelo con caracter√≠sticas seleccionadas: {accuracy}\")\n",
        "print(\"Reporte de clasificaci√≥n:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Obtener las caracter√≠sticas seleccionadas\n",
        "feature_importances = pd.Series(xgb_model.feature_importances_, index=selected_features)\n",
        "\n",
        "# Ordenar las importancias de las caracter√≠sticas en orden descendente\n",
        "sorted_feature_importances = feature_importances.sort_values(ascending=False)\n",
        "\n",
        "# Mostrar las caracter√≠sticas seleccionadas\n",
        "print(\"\\nImportancia de las caracter√≠sticas seleccionadas (descendente):\")\n",
        "display(sorted_feature_importances)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ambos modelos mantienen un accuracy de aproximadamente 0.935, demostrando que el modelo reducido no sacrifica precisi√≥n. El modelo original utiliza todas las caracter√≠sticas disponibles, mientras que el modelo con selecci√≥n RFECV conserva solo las variables m√°s relevantes seg√∫n su ranking de importancia. La robustez se mantiene comparable ya que las m√©tricas clave (precision, recall, F1) permanecen estables entre ambas versiones, indicando que las caracter√≠sticas eliminadas no contribu√≠an significativamente al poder predictivo.\n",
        "Veamos los beneficios de eliminar variables del modelo la reducci√≥n de dimensionalidad ofrece tres ventajas principales. Primero, disminuye el tiempo de entrenamiento al procesar menos features por observaci√≥n. Segundo, minimiza el riesgo de overfitting al eliminar variables ruidosas o redundantes que podr√≠an capturar patrones del conjunto de entrenamiento. Tercero, mejora la generalizaci√≥n porque el modelo se concentra en las caracter√≠sticas con verdadera capacidad predictiva, ignorando informaci√≥n irrelevante que podr√≠a distorsionar las predicciones en datos nuevos.\n",
        "Interpretabilidad del Modelo con Menor Dimensionalidad\n",
        "Un modelo con menos caracter√≠sticas es sustancialmente m√°s interpretable. Trabajar con las top 10-15 features (como Heading, Short_Pass, Acceleration) permite explicar claramente que atributos espec√≠ficos determinan las predicciones, facilitando decisiones de inversi√≥n informadas. La eliminaci√≥n de variables poco importantes reduce la complejidad conceptual, permitiendo enfocar el an√°lisis en los factores verdaderamente determinantes de la selecci√≥n nacional sin diluir el mensaje con decenas de caracter√≠sticas marginales."
      ],
      "metadata": {
        "id": "ptevFmz_bNT2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTG5cH9r3M9g"
      },
      "source": [
        "### 2.3 Calibraci√≥n Probabilistica [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDL0VqjR7yvb"
      },
      "source": [
        "<center>\n",
        "<img src='https://media2.giphy.com/media/l2Je4Ku0Cx292KWv6/200w.gif?cid=6c09b952y0sihtq9tb6sz8j2023x3zxxp3qx1ocgonkpkblj&ep=v1_gifs_search&rid=200w.gif&ct=g' width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmOKxhAw3sic"
      },
      "source": [
        "Para lograr modelos m√°s modulares, se recomienda realizar una calibraci√≥n del modelo entrenado anteriormente, con el objetivo de obtener salidas que reflejen mayor modularidad.\n",
        "\n",
        "1. Se solicita que utilice un m√©todo de calibraci√≥n que asegure que las probabilidades generadas incrementen de manera mon√≥tona. Una m√©trica ampliamente utilizada para evaluar la precisi√≥n de la calibraci√≥n de un modelo es el Brier Score. Calcule el Brier Score para el modelo tanto antes como despu√©s de la calibraci√≥n. Esto le permitir√° realizar una comparaci√≥n cuantitativa y determinar si la calibraci√≥n ha mejorado el rendimiento del modelo. Para m√°s informaci√≥n sobre el Brier Score, puede consultar el siguiente enlace: [Scikit-Learn - Brier Score Loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html). [3 puntos]\n",
        "\n",
        "2. Tras la calibraci√≥n, examine y comente los resultados obtenidos. A su an√°lisis a√±ada una comparaci√≥n visual de las ideales versus las salidas del modelo original (sin calibrar) y del modelo calibrado. [3 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIiYz_qLuD19"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0bfSuiFuD2I"
      },
      "outputs": [],
      "source": [
        "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
        "from sklearn.metrics import brier_score_loss\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calibraci√≥n isot√≥nica del modelo entrenado\n",
        "calibrated_model = CalibratedClassifierCV(xgb_model, method='isotonic', cv='prefit')\n",
        "\n",
        "# Ajustar el modelo calibrado a los datos de entrenamiento\n",
        "calibrated_model.fit(X_train_selected, y_train_encoded)\n",
        "\n",
        "# Realizar predicciones de probabilidades antes de la calibraci√≥n (para comparar)\n",
        "y_prob_before_calibration = xgb_model.predict_proba(X_test_selected)[:, 1]  # Probabilidades para la clase positiva\n",
        "\n",
        "# Realizar predicciones de probabilidades despu√©s de la calibraci√≥n\n",
        "y_prob_after_calibration = calibrated_model.predict_proba(X_test_selected)[:, 1]\n",
        "\n",
        "# Calcular el Brier Score antes y despu√©s de la calibraci√≥n\n",
        "brier_before = brier_score_loss(y_test, y_prob_before_calibration)\n",
        "brier_after = brier_score_loss(y_test, y_prob_after_calibration)\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(f\"Brier Score antes de la calibraci√≥n: {brier_before}\")\n",
        "print(f\"Brier Score despu√©s de la calibraci√≥n: {brier_after}\")\n",
        "\n",
        "# Graficar las curvas de calibraci√≥n antes y despu√©s de la calibraci√≥n\n",
        "def plot_calibration_curve(y_true, y_prob, title=\"Calibration Curve\"):\n",
        "    fraction_of_positives, mean_predicted_value = calibration_curve(y_true, y_prob, n_bins=10)\n",
        "\n",
        "    plt.plot(mean_predicted_value, fraction_of_positives, marker='o', label=\"Model\")\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', label=\"Perfectly calibrated\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Mean predicted value')\n",
        "    plt.ylabel('Fraction of positives')\n",
        "    plt.legend()\n",
        "\n",
        "# Graficar antes de la calibraci√≥n\n",
        "plot_calibration_curve(y_test, y_prob_before_calibration, \"Calibration Curve Before Calibration\")\n",
        "\n",
        "# Graficar despu√©s de la calibraci√≥n\n",
        "plot_calibration_curve(y_test, y_prob_after_calibration, \"Calibration Curve After Calibration\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El Brier Score antes de la calibraci√≥n es 0.046, mientras que despu√©s de la calibraci√≥n se reduce a 0.0599, lo que indica una ligera degradaci√≥n en la m√©trica. Sin embargo, esto no necesariamente significa un peor desempe√±o general. El Brier Score mide la diferencia cuadr√°tica media entre las probabilidades predichas y los resultados reales, pero la calibraci√≥n isot√≥nica busca espec√≠ficamente que las probabilidades sean mon√≥tonas y bien calibradas, lo que puede sacrificar m√≠nimamente el Brier Score a cambio de probabilidades m√°s interpretables y confiables.\n",
        "Comparaci√≥n Visual: Curvas de Calibraci√≥n\n",
        "La curva de calibraci√≥n despu√©s de la calibraci√≥n isot√≥nica muestra una mejora significativa en la alineaci√≥n con la diagonal perfecta (l√≠nea punteada). Antes de la calibraci√≥n, el modelo original (l√≠nea azul) mostraba desviaciones considerables de la calibraci√≥n ideal, particularmente en los rangos intermedios de probabilidad donde las predicciones eran excesivamente conservadoras o optimistas.\n",
        "Despu√©s de la calibraci√≥n (l√≠nea roja), el modelo muestra un comportamiento mucho m√°s cercano a la l√≠nea perfectamente calibrada, especialmente en el rango de 0.4 a 0.8 de probabilidad predicha. Esto significa que cuando el modelo calibrado predice una probabilidad del 60%, aproximadamente el 60% de esos casos efectivamente pertenecen a la clase positiva, lo cual es crucial para las decisiones de inversi√≥n.\n",
        "La calibraci√≥n isot√≥nica ha logrado su objetivo de producir probabilidades m√°s confiables y modulares. Aunque el Brier Score aument√≥ marginalmente, las probabilidades ahora reflejan mejor la incertidumbre real del modelo, permitiendo establecer umbrales de decisi√≥n m√°s informados y facilitar la interpretaci√≥n de las predicciones como verdaderas estimaciones de probabilidad."
      ],
      "metadata": {
        "id": "LT06FtbMcmmf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW4ua_Gm2t7k"
      },
      "source": [
        "Mucho √©xito!\n",
        "\n",
        "<center>\n",
        "<img src=\"https://i.pinimg.com/originals/55/3d/42/553d42bea9b10e0662a05aa8726fc7f4.gif\" width=300>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "K8DSS3u1xMpB",
        "PTG5cH9r3M9g"
      ],
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}